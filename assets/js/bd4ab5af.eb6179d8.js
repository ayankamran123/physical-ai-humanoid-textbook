"use strict";(globalThis.webpackChunkbook=globalThis.webpackChunkbook||[]).push([[3986],{3082:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"chapter-01","title":"Chapter 1","description":"Foundations of Physical AI & Robot Kinematics","source":"@site/docs/chapter-01.md","sourceDirName":".","slug":"/chapter-01","permalink":"/physical-ai-humanoid-textbook/docs/chapter-01","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/chapter-01.md","tags":[],"version":"current","frontMatter":{"id":"chapter-01","title":"Chapter 1","sidebar_label":"Chapter 1"},"sidebar":"tutorialSidebar","next":{"title":"Chapter 2","permalink":"/physical-ai-humanoid-textbook/docs/chapter-02"}}');var t=i(4848),a=i(8453);const o={id:"chapter-01",title:"Chapter 1",sidebar_label:"Chapter 1"},r=void 0,l={},c=[{value:"Foundations of Physical AI &amp; Robot Kinematics",id:"foundations-of-physical-ai--robot-kinematics",level:3},{value:"1. What Is Physical AI?",id:"1-what-is-physical-ai",level:2},{value:"2. How Robotics &amp; AI Came Together",id:"2-how-robotics--ai-came-together",level:2},{value:"Short Timeline",id:"short-timeline",level:3},{value:"Learning Objectivesa",id:"learning-objectivesa",level:4},{value:"Theory Explanation",id:"theory-explanation",level:4},{value:"Diagrams",id:"diagrams",level:4},{value:"Python/ROS2 Code Examples",id:"pythonros2-code-examples",level:4},{value:"1. Homogeneous Transformation, 2D FK, and Conceptual Jacobian for Planar Arm (Python)",id:"1-homogeneous-transformation-2d-fk-and-conceptual-jacobian-for-planar-arm-python",level:5},{value:"2. Simple Reactive Control Loop (Python)",id:"2-simple-reactive-control-loop-python",level:5},{value:"Exercises + MCQs",id:"exercises--mcqs",level:4},{value:"Exercises",id:"exercises",level:5},{value:"Multiple Choice Questions",id:"multiple-choice-questions",level:5}];function d(e){const n={admonition:"admonition",br:"br",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",h5:"h5",hr:"hr",input:"input",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h3,{id:"foundations-of-physical-ai--robot-kinematics",children:"Foundations of Physical AI & Robot Kinematics"}),"\n",(0,t.jsx)(n.h2,{id:"1-what-is-physical-ai",children:"1. What Is Physical AI?"}),"\n",(0,t.jsxs)(n.p,{children:["Physical AI is the branch of artificial intelligence that controls ",(0,t.jsx)(n.strong,{children:"real-world robots"}),".",(0,t.jsx)(n.br,{}),"\n","It combines:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Sensing"}),"\n",(0,t.jsx)(n.li,{children:"Understanding"}),"\n",(0,t.jsx)(n.li,{children:"Decision-making"}),"\n",(0,t.jsx)(n.li,{children:"Physical actions"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Unlike software AI, Physical AI must handle:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Noise"}),"\n",(0,t.jsx)(n.li,{children:"Real surfaces, physics, and collisions"}),"\n",(0,t.jsx)(n.li,{children:"Real-time safety"}),"\n",(0,t.jsx)(n.li,{children:"Uncertainty"}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"2-how-robotics--ai-came-together",children:"2. How Robotics & AI Came Together"}),"\n",(0,t.jsx)(n.h3,{id:"short-timeline",children:"Short Timeline"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Early Cybernetics:"})," Simple feedback systems"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"1950s\u201380s:"})," Industrial robots + symbolic AI"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"1990s\u20132000s:"})," Mobile robots, control theory"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"2010s\u2013Now:"})," Deep learning + humanoids"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Current Era:"})," Embodied intelligence (AI inside physical bodies)"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"learning-objectivesa",children:"Learning Objectivesa"}),"\n",(0,t.jsx)(n.p,{children:"After studying this chapter, you should be able to:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Define Physical AI, distinguish it from traditional software AI, and trace the historical convergence of AI and robotics."}),"\n",(0,t.jsx)(n.li,{children:"Identify the core interdisciplinary components of humanoid robotics, including hardware, software, and control."}),"\n",(0,t.jsx)(n.li,{children:"Systematically apply Forward Kinematics (FK) and Inverse Kinematics (IK) concepts to robotic systems."}),"\n",(0,t.jsx)(n.li,{children:"Utilize Homogeneous Transformation Matrices (HTMs) and the Denavit-Hartenberg (DH) convention for representing robot poses and kinematics."}),"\n",(0,t.jsx)(n.li,{children:"Understand the role and significance of the Jacobian matrix in velocity analysis, singularity detection, and static force analysis for robot manipulators."}),"\n",(0,t.jsx)(n.li,{children:"Evaluate the ethical implications of physical AI deployment, considering safety, autonomy, and societal impact."}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"theory-explanation",children:"Theory Explanation"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"1.1 Introduction to Physical AI: Bridging the Digital and Physical"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Physical Artificial Intelligence (Physical AI)"})," represents the cutting edge of AI, integrating intelligent capabilities directly into physical robots, enabling them to perceive, reason, and act autonomously within the real world. Unlike purely software-based AI (e.g., large language models, recommendation engines) that operates solely in digital environments, embodied AI systems face unique challenges inherent to physical existence:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Real-world Perception"}),": Processing noisy, incomplete, and high-dimensional data from diverse sensors (cameras, LiDAR, tactile sensors) in dynamic, unstructured environments."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Embodied Action"}),": Translating high-level decisions into precise physical motions through actuators, respecting mechanical constraints, compliance requirements, and energy budgets."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Safe Interaction"}),": Operating in real-time while safely interacting with the environment, objects, and particularly humans, often in unpredictable scenarios."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Uncertainty Management"}),": Continuously adapting to the inherent unpredictability and variability of the physical world, which is often abstracted away in purely software simulations."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"The overarching goal of Physical AI is to extend AI's problem-solving prowess into tangible physical spaces, allowing robots to perform complex tasks that demand manipulation, navigation, and dexterous interaction."}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"1.2 Historical Convergence of Robotics and AI"})}),"\n",(0,t.jsx)(n.p,{children:"The paths of robotics and artificial intelligence, once separate, have increasingly converged to form the modern field of Physical AI."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Early Seeds (Pre-1950s)"}),": From ancient automatons to the mid-20th century emergence of ",(0,t.jsx)(n.strong,{children:"Cybernetics"})," (Norbert Wiener), the theoretical groundwork for feedback control and communication in machines and organisms was laid."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Birth of AI and Industrial Automation (1950s-1970s)"}),': The term "Artificial Intelligence" was coined in 1956. Early AI focused on symbolic reasoning. Concurrently, the first industrial robots (e.g., George Devol\'s Unimate) revolutionized manufacturing with programmable, repetitive tasks, lacking true intelligence.']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Challenges and Refinements (1980s-1990s)"}),': "AI Winters" led to a focus on specialized AI and robust control theory in robotics. Mobile robots gained basic navigation, and humanoid research began (e.g., Honda ASIMO, 1986), emphasizing complex control for bipedalism.']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Machine Learning Renaissance (2000s-2010s)"}),": Statistical machine learning revitalized AI. Robots integrated more sophisticated perception (computer vision for object recognition) and learning. Humanoids demonstrated advanced capabilities in walking, running, and manipulation due to better hardware and algorithms."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Deep Learning and Embodied AI (2010s-Present)"}),": Deep learning brought breakthroughs in perception and decision-making, leading to the ",(0,t.jsx)(n.strong,{children:"Embodied AI"})," paradigm. Deep learning models are now directly integrated into robot control, enabling learning from vast datasets and adaptive task execution. Modern humanoids are key platforms for this advanced research."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"1.3 Components and Interdisciplinary Nature of Humanoid Robotics"})}),"\n",(0,t.jsx)(n.p,{children:"Humanoid robotics is a profoundly interdisciplinary field, synthesizing knowledge from diverse domains to create robots that mimic human form and function."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Hardware (The Body)"}),":","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Mechanical Design"}),": Body frame, linkages, joints, materials science (lightweight, strong alloys, composites)."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Actuation"}),": Motors (DC, servo, stepper, BLDC), gearboxes, hydraulics, pneumatics, artificial muscles for movement generation."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sensing"}),": Cameras (stereo, depth), LiDAR, IMUs (accelerometers, gyroscopes, magnetometers), force/torque, tactile sensors, microphones for perception."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Power Systems"}),": Batteries, power management, energy efficiency."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Software and Control (The Brain and Nervous System)"}),":","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Perception"}),": Computer vision, audio processing, sensor fusion, SLAM (Simultaneous Localization and Mapping) for interpreting raw sensor data."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Control Theory"}),": PID, state-space, optimal, impedance control for regulating joint movements and stability."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Motion Planning"}),": Path planning, trajectory generation, whole-body control, grasp planning for determining ",(0,t.jsx)(n.em,{children:"how"})," to move."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Artificial Intelligence/Machine Learning"}),": Reinforcement learning, imitation learning, deep learning for adaptive control and decision-making."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Human-Robot Interaction (HRI)"}),": Gesture/speech recognition, social navigation for natural collaboration."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Robotics Middleware"}),": Frameworks like ROS2 (Robot Operating System 2) providing communication infrastructure."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"1.4 Robot Kinematics: The Geometry of Motion"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Robot Kinematics"})," is the study of robot motion without considering forces or torques. It focuses on the geometric relationships between joint variables and the end-effector's position and orientation."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"1.4.1 Forward Kinematics (FK)"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Forward Kinematics (FK)"})," is the deterministic mapping from joint space to task space. Given all joint variables (",(0,t.jsx)(n.code,{children:"q"}),"), FK calculates the end-effector's pose (",(0,t.jsx)(n.code,{children:"X"}),") relative to a base frame. This is typically a straightforward computation involving successive transformation matrix multiplications: ",(0,t.jsx)(n.code,{children:"X = f(q)"}),"."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Applications"}),": Visualization, collision detection, generating sensor expectations."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"1.4.2 Inverse Kinematics (IK)"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Inverse Kinematics (IK)"})," is the inverse problem: given a desired end-effector pose (",(0,t.jsx)(n.code,{children:"X"}),"), determine the joint variables (",(0,t.jsx)(n.code,{children:"q"}),") that achieve it. IK is significantly more complex due to:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Non-linearity"}),": Complex relationships between joint and task space."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Multiple Solutions"}),": A pose can often be reached by several joint configurations."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"No Solutions"}),": The desired pose might be outside the robot's workspace."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Singularities"}),": Joint configurations where the robot loses task-space degrees of freedom."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"IK is solved using analytical or numerical methods (e.g., Jacobian-based)."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Applications"}),": Task-space control, human-robot collaboration, path planning."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"1.5 Homogeneous Transformation Matrices (HTMs) and Denavit-Hartenberg (DH) Convention"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Homogeneous Transformation Matrices (HTMs)"})," are 4x4 matrices that combine 3D rotation and translation into a single entity, ",(0,t.jsx)(n.code,{children:"T = [[R_{3x3}, p_{3x1}], [0_{1x3}, 1_{1x1}]]"}),". They allow for seamless composition of transformations via matrix multiplication."]}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.strong,{children:"Denavit-Hartenberg (DH) Convention"})," provides a systematic method for assigning coordinate frames to each link of a serial robot. For each link ",(0,t.jsx)(n.code,{children:"i"}),", a transformation from frame ",(0,t.jsx)(n.code,{children:"{i-1}"})," to ",(0,t.jsx)(n.code,{children:"{i}"})," is defined by four parameters:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"-i"})," (Link Length): Distance along common normal."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"\u03b1_i"})," (Link Twist): Angle between ",(0,t.jsx)(n.code,{children:"z"})," axes about common normal."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"d_i"})," (Link Offset): Distance along ",(0,t.jsx)(n.code,{children:"z_{i-1}"})," to common normal."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"\u03b8_i"})," (Joint Angle): Angle between ",(0,t.jsx)(n.code,{children:"x"})," axes about ",(0,t.jsx)(n.code,{children:"z_{i-1}"}),". (Joint variable for revolute joints)."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["The full FK is ",(0,t.jsx)(n.code,{children:"T_N^0 = A_1^0 A_2^1 ... A_N^{N-1}"}),", where ",(0,t.jsx)(n.code,{children:"A_i^{i-1}"})," is the DH transformation matrix."]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"1.6 The Jacobian Matrix: Joint to Task Space Velocity"})}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsxs)(n.strong,{children:["Jacobian Matrix (",(0,t.jsx)(n.code,{children:"J"}),")"]})," is a fundamental tool relating joint velocities (",(0,t.jsx)(n.code,{children:"q\u0307"}),") to end-effector linear (",(0,t.jsx)(n.code,{children:"v"}),") and angular (",(0,t.jsx)(n.code,{children:"\u03c9"}),") velocities in task space: ",(0,t.jsx)(n.code,{children:"[v; \u03c9] = J(q) * q\u0307"}),"."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Velocity Analysis"}),": Directly maps joint velocities to end-effector velocities."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Inverse Kinematics"}),": Used in numerical IK to find joint velocities for desired end-effector velocities (",(0,t.jsx)(n.code,{children:"q\u0307 = J\u207a(q) * [v; \u03c9]"}),")."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Singularity Analysis"}),": Singularities occur when ",(0,t.jsx)(n.code,{children:"J"})," loses rank (determinant is zero), leading to a loss of task-space DoF. These must be avoided."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Static Force Analysis"}),": ",(0,t.jsx)(n.code,{children:"\u03c4 = J^T * F"})," relates task-space forces to joint torques."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"1.7 Ethical Considerations in Physical AI"})}),"\n",(0,t.jsx)(n.p,{children:"The deployment of physical AI raises critical ethical questions:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Safety and Reliability"}),": Ensuring physical safety and liability in accidents."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Autonomy and Accountability"}),": Determining responsibility for autonomous robot decisions."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Privacy and Surveillance"}),": Protecting data collected by robot sensors."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Bias and Discrimination"}),": Preventing discriminatory behaviors from biased AI models."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Socio-Economic Impact"}),": Addressing job displacement and economic inequality."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Human Dignity"}),": Impact on human relationships and perception of uniqueness."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Transparency and Explainability"}),": Understanding autonomous robot decision-making."]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Proactive ethical design, robust guidelines, and continuous public dialogue are essential."}),"\n",(0,t.jsx)(n.h4,{id:"diagrams",children:"Diagrams"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-mermaid",children:"graph TD\n    subgraph Physical AI Ecosystem\n        S[Sensors] --\x3e P(Perception & State Estimation);\n        A[Actuators] --\x3e C(Control & Motion Generation);\n        P --\x3e AI(AI & ML Algorithms);\n        AI --\x3e C;\n        C --\x3e A;\n        P <--\x3e Env(Physical Environment);\n        C <--\x3e Env;\n        AI -- Influences --\x3e Eth(Ethics & Safety Considerations);\n        Eth -- Informs --\x3e Design(Robot Design & Deployment);\n    end\n\n    subgraph Robot Kinematics\n        FK[Forward Kinematics] -- q --\x3e EE_Pose(End-Effector Pose);\n        EE_Pose -- X --\x3e IK[Inverse Kinematics];\n        IK -- q --\x3e FK;\n\n        subgraph DH Parameters\n            L1(Link 1 DH) --\x3e TM1(Transform Matrix 1);\n            L2(Link 2 DH) --\x3e TM2(Transform Matrix 2);\n            TM1 --\x3e TM_COMPOSITION(Composition of HTMs);\n            TM2 --\x3e TM_COMPOSITION;\n            TM_COMPOSITION --\x3e EE_Pose;\n        end\n\n        subgraph Jacobian Analysis\n            JV(Joint Velocities q_dot) --\x3e JM(Jacobian Matrix J(q));\n            JM --\x3e TV(Task Space Velocities [v, omega]);\n            JM --\x3e Singularities(Singularity Analysis);\n        end\n    end\n    AI -- Integrates with --\x3e JV;\n    C -- Driven by --\x3e JV;\n    EE_Pose -- Guides --\x3e P;\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Figure 1.1: Integrated View of Physical AI and Robot Kinematics"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-mermaid",children:"graph LR\n    FK_Input(Joint Angles) --\x3e FK_Process(Geometric Calculations) --\x3e FK_Output(End-Effector Pose);\n    IK_Input(Desired End-Effector Pose) --\x3e IK_Process(Solver Algorithm) --\x3e IK_Output(Joint Angles);\n\n    FK_Output -- Used by --\x3e IK_Input;\n    IK_Output -- Controls --\x3e FK_Input;\n\n    subgraph Homogeneous Transforms\n        Rotation(Rotation Matrix) & Translation(Translation Vector) --\x3e HTM(HTM Construction);\n        HTM1(HTM A) & HTM2(HTM B) --\x3e Composition(HTM Composition: A*B);\n    end\n\n    subgraph Jacobian Dynamics\n        Joint_Vel(Joint Velocities) --\x3e Jacobian(Jacobian Matrix);\n        Jacobian --\x3e EE_Vel(End-Effector Velocities);\n        Jacobian --\x3e Singularities_Det(Singularity Detection: Det(J)=0);\n    end\n\n    FK_Process -- Uses --\x3e Composition;\n    IK_Process -- Uses --\x3e Jacobian;\n    Joint_Vel -- Feeds --\x3e Jacobian;\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Figure 1.2: Kinematics Details: FK, IK, HTM, and Jacobian"})}),"\n",(0,t.jsx)(n.h4,{id:"pythonros2-code-examples",children:"Python/ROS2 Code Examples"}),"\n",(0,t.jsx)(n.h5,{id:"1-homogeneous-transformation-2d-fk-and-conceptual-jacobian-for-planar-arm-python",children:"1. Homogeneous Transformation, 2D FK, and Conceptual Jacobian for Planar Arm (Python)"}),"\n",(0,t.jsx)(n.p,{children:"This comprehensive example combines functions for 2D rotations, translations, constructing homogeneous transformation matrices, and applies them to a 2-DOF planar arm to calculate its forward kinematics and conceptual Jacobian."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import numpy as np\nimport math\n\ndef rot_z(angle_rad):\n    """Generates a 2D rotation matrix around the Z-axis (for 3D context, this is a Z-rotation)."""\n    c = math.cos(angle_rad)\n    s = math.sin(angle_rad)\n    return np.array([[c, -s, 0],\n                     [s,  c, 0],\n                     [0,  0, 1]])\n\ndef trans_xyz(x, y, z):\n    """Generates a 3D translation vector."""\n    return np.array([x, y, z])\n\ndef homogeneous_transform_matrix(rotation_matrix, translation_vector):\n    """Constructs a 4x4 homogeneous transformation matrix.\n    rotation_matrix: 3x3 numpy array\n    translation_vector: 3x1 numpy array\n    """\n    T = np.eye(4)\n    T[:3, :3] = rotation_matrix\n    T[:3, 3] = translation_vector\n    return T\n\ndef forward_kinematics_2d_planar_arm(L1, L2, theta1_rad, theta2_rad):\n    """Calculates the end-effector position (x, y) for a 2-DOF planar arm.\n    L1, L2: Link lengths\n    theta1_rad, theta2_rad: Joint angles in radians (from the previous link or base)\n    """\n    # Position of joint 1 (relative to base, which is origin)\n    x1 = L1 * math.cos(theta1_rad)\n    y1 = L1 * math.sin(theta1_rad)\n\n    # Position of end-effector (relative to base)\n    # The angle for the second link is relative to the first link\n    x_ee = x1 + L2 * math.cos(theta1_rad + theta2_rad)\n    y_ee = y1 + L2 * math.sin(theta1_rad + theta2_rad)\n\n    return x_ee, y_ee\n\ndef calculate_jacobian_2d_planar_arm(L1, L2, theta1_rad, theta2_rad):\n    """Calculates the Jacobian matrix for a 2-DOF planar arm.\n    J relates [theta1_dot, theta2_dot] to [x_dot, y_dot].\n    """\n    # Partial derivatives of x_ee and y_ee with respect to theta1 and theta2\n    # x_ee = L1 * cos(theta1) + L2 * cos(theta1 + theta2)\n    # y_ee = L1 * sin(theta1) + L2 * sin(theta1 + theta2)\n\n    # dx_ee/d(theta1)\n    J11 = -L1 * math.sin(theta1_rad) - L2 * math.sin(theta1_rad + theta2_rad)\n    # dx_ee/d(theta2)\n    J12 = -L2 * math.sin(theta1_rad + theta2_rad)\n\n    # dy_ee/d(theta1)\n    J21 = L1 * math.cos(theta1_rad) + L2 * math.cos(theta1_rad + theta2_rad)\n    # dy_ee/d(theta2)\n    J22 = L2 * math.cos(theta1_rad + theta2_rad)\n\n    Jacobian = np.array([\n        [J11, J12],\n        [J21, J22]\n    ])\n    return Jacobian\n\nif __name__ == "__main__":\n    # Example: 2-DOF planar arm FK\n    link1_length = 1.0  # meters\n    link2_length = 0.8  # meters\n    joint1_angle = math.pi / 6  # 30 degrees\n    joint2_angle = math.pi / 4  # 45 degrees\n\n    ee_x, ee_y = forward_kinematics_2d_planar_arm(link1_length, link2_length, joint1_angle, joint2_angle)\n    print(f"End-effector position for 2-DOF arm: ({ee_x:.3f}, {ee_y:.3f}) meters")\n\n    # Example: Constructing and composing Homogeneous Transformation Matrices\n    R0_1 = rot_z(math.pi / 4) # Rotate 45 deg around Z\n    p0_1 = trans_xyz(0.5, 0.2, 0.0) # Translate by (0.5, 0.2, 0)\n    T0_1 = homogeneous_transform_matrix(R0_1, p0_1)\n    print("\nTransformation T0_1 (Frame 0 to Frame 1):\n", T0_1)\n\n    R1_2 = np.eye(3) # No rotation\n    p1_2 = trans_xyz(0.3, 0.0, 0.0) # Translate by (0.3, 0, 0) along its own X\n    T1_2 = homogeneous_transform_matrix(R1_2, p1_2)\n    print("\nTransformation T1_2 (Frame 1 to Frame 2):\n", T1_2)\n\n    T0_2 = np.dot(T0_1, T1_2)\n    print("\nComposed Transformation T0_2 (Frame 0 to Frame 2):\n", T0_2)\n\n    # Example: Jacobian and Singularity Check\n    J_arm = calculate_jacobian_2d_planar_arm(link1_length, link2_length, joint1_angle, joint2_angle)\n    print("\nJacobian Matrix for 2-DOF Planar Arm:\n", np.array2string(J_arm, precision=3, separator=\',\', suppress_small=True))\n\n    det_J = np.linalg.det(J_arm)\n    print(f"\nDeterminant of Jacobian: {det_J:.3f}")\n    if abs(det_J) < 1e-6:\n        print("Warning: Robot is near a kinematic singularity!")\n    else:\n        print("Robot is in a non-singular configuration.")\n\n    # Example of a singular configuration (arm fully extended or folded)\n    print("\n--- Testing a Singular Configuration ---")\n    singular_J = calculate_jacobian_2d_planar_arm(1.0, 1.0, 0.0, 0.0) # Fully extended\n    print("Jacobian at singular config (theta1=0, theta2=0):\n", np.array2string(singular_J, precision=3, separator=\',\', suppress_small=True))\n    print(f"Determinant: {np.linalg.det(singular_J):.3f}")\n    if abs(np.linalg.det(singular_J)) < 1e-6:\n        print("Correctly identified singularity.")\n'})}),"\n",(0,t.jsx)(n.h5,{id:"2-simple-reactive-control-loop-python",children:"2. Simple Reactive Control Loop (Python)"}),"\n",(0,t.jsx)(n.p,{children:"This example simulates a robot reacting to a proximity sensor, illustrating basic state management and control logic, which underpins how physical AI systems make decisions based on sensory input."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import time\nimport random\n\nclass RobotState:\n    def __init__(self):\n        self.current_distance = float(\'inf\') # meters\n        self.current_speed = 0.0             # m/s\n        self.mode = "idle"                   # "idle", "moving", "avoiding"\n\nclass RobotController:\n    def __init__(self, robot_state: RobotState):\n        self.state = robot_state\n        self.max_speed = 0.8\n        self.safe_distance = 0.7 # meters\n        self.critical_distance = 0.3 # meters\n        print("RobotController initialized.")\n\n    def read_proximity_sensor(self):\n        # Simulate reading a noisy proximity sensor\n        noise = random.uniform(-0.05, 0.05)\n        if self.state.current_distance == float(\'inf\'):\n            new_distance = random.uniform(1.0, 5.0) + noise\n        else:\n            new_distance = self.state.current_distance + random.uniform(-0.2, 0.2) + noise\n        self.state.current_distance = max(0.0, new_distance) # Distance cannot be negative\n        # print(f"Sensor read: {self.state.current_distance:.2f}m") # Uncomment for verbose output\n\n    def set_motor_speed(self, linear_speed):\n        # Simulate sending command to motor actuators\n        self.state.current_speed = max(0.0, min(self.max_speed, linear_speed))\n        # print(f"Motor speed set to: {self.state.current_speed:.2f} m/s") # Uncomment for verbose output\n\n    def update_robot_behavior(self):\n        distance = self.state.current_distance\n        current_speed = self.state.current_speed\n\n        if distance < self.critical_distance:\n            if self.state.mode != "avoiding" or current_speed > 0.0:\n                self.set_motor_speed(0.0)\n                self.state.mode = "avoiding"\n                print("CRITICAL: Obstacle too close! Full stop.")\n        elif distance < self.safe_distance:\n            if self.state.mode != "avoiding" or current_speed > 0.2:\n                self.set_motor_speed(0.2) # Slow creep\n                self.state.mode = "avoiding"\n                print("WARNING: Obstacle near. Slowing down.")\n        else:\n            if self.state.mode != "moving" or current_speed < self.max_speed:\n                self.set_motor_speed(self.max_speed)\n                self.state.mode = "moving"\n                print("INFO: Path clear. Moving forward.")\n\n    def run_simulation(self, duration_seconds):\n        start_time = time.time()\n        print("Starting robot simulation...")\n        while (time.time() - start_time) < duration_seconds:\n            self.read_proximity_sensor()\n            self.update_robot_behavior()\n            time.sleep(0.5) # Simulate real-time processing interval\n        self.set_motor_speed(0.0) # Ensure robot stops at end\n        print("Simulation finished.")\n\nif __name__ == "__main__":\n    robot_state = RobotState()\n    robot_controller = RobotController(robot_state)\n    robot_controller.run_simulation(duration_seconds=10)\n'})}),"\n",(0,t.jsx)(n.h4,{id:"exercises--mcqs",children:"Exercises + MCQs"}),"\n",(0,t.jsx)(n.h5,{id:"exercises",children:"Exercises"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Physical AI vs. Software AI"}),": Provide a detailed example of a task where a purely software AI would excel but a physical AI would struggle, and vice-versa. Explain the underlying reasons based on the challenges unique to embodied systems."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Kinematic Design Choice"}),": You are designing a robotic arm for fine manipulation in a confined space. Would you prioritize a high number of degrees of freedom (DoF) or a simpler kinematic structure? Justify your choice by discussing the trade-offs in terms of FK/IK complexity, control, and singularity avoidance."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Jacobian Interpretation"}),": For the 2-DOF planar arm Jacobian example provided, what does a column vector ",(0,t.jsx)(n.code,{children:"[J12, J22]^T"})," represent? If ",(0,t.jsx)(n.code,{children:"J12"})," and ",(0,t.jsx)(n.code,{children:"J22"})," were both zero, what would that imply about the robot's movement capabilities related to ",(0,t.jsx)(n.code,{children:"theta2_dot"}),"?"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Ethical Scenario"}),": A humanoid robot designed for elderly care develops a bug that causes it to occasionally ignore verbal commands. Analyze this scenario through the lens of ethical considerations discussed (Safety, Autonomy, Transparency). What safeguards should have been in place during design and deployment?"]}),"\n"]}),"\n",(0,t.jsx)(n.h5,{id:"multiple-choice-questions",children:"Multiple Choice Questions"}),"\n",(0,t.jsxs)(n.admonition,{type:"info",children:[(0,t.jsxs)(n.p,{children:["Which of the following is a primary challenge for ",(0,t.jsx)(n.strong,{children:"Physical AI"})," that is less prominent for purely software-based AI?"]}),(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Processing large datasets."]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Generating natural language."]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",checked:!0,disabled:!0})," ","Operating in real-time within noisy, uncertain physical environments."]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Performing complex mathematical computations."]}),"\n"]})]}),"\n",(0,t.jsxs)(n.admonition,{type:"info",children:[(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.strong,{children:"Denavit-Hartenberg (DH) Convention"})," is primarily used for:"]}),(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Determining the optimal materials for robot links."]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Calculating the forces exerted by robot joints."]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",checked:!0,disabled:!0})," ","Systematically assigning coordinate frames and deriving kinematic parameters for serial robots."]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Designing the power systems of a robot."]}),"\n"]})]}),"\n",(0,t.jsxs)(n.admonition,{type:"info",children:[(0,t.jsxs)(n.p,{children:["If a robot's ",(0,t.jsx)(n.strong,{children:"Jacobian matrix"})," has a determinant of zero at a particular configuration, the robot is said to be in a:"]}),(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Stable equilibrium."]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","Optimal working pose."]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",checked:!0,disabled:!0})," ","Kinematic singularity."]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","High-dexterity region."]}),"\n"]})]}),"\n",(0,t.jsxs)(n.admonition,{type:"info",children:[(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Inverse Kinematics (IK)"})," typically involves finding:"]}),(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","The end-effector pose given joint angles."]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",checked:!0,disabled:!0})," ","The joint angles required to achieve a desired end-effector pose."]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","The velocities of the robot's links."]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","The energy consumption of the robot."]}),"\n"]})]}),"\n",(0,t.jsxs)(n.admonition,{type:"info",children:[(0,t.jsxs)(n.p,{children:["An ethical concern regarding ",(0,t.jsx)(n.strong,{children:"robot autonomy"})," most directly relates to:"]}),(0,t.jsxs)(n.ul,{className:"contains-task-list",children:["\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","The robot's ability to move without external power."]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","The physical size and weight of the robot."]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",checked:!0,disabled:!0})," ","Who is accountable when an autonomous robot makes an unpredicted decision."]}),"\n",(0,t.jsxs)(n.li,{className:"task-list-item",children:[(0,t.jsx)(n.input,{type:"checkbox",disabled:!0})," ","The speed at which the robot can complete tasks."]}),"\n"]})]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>r});var s=i(6540);const t={},a=s.createContext(t);function o(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);